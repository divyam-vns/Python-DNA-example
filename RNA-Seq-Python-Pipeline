# ===========================================
# NGS Python Pipeline with README and Synthetic Data
# ===========================================

# This repo demonstrates a simple RNA-Seq analysis workflow using Python libraries:
# pandas, NumPy, and scikit-learn, with synthetic data included for immediate use.

# Directory structure:
# ngs_python_pipeline/
# ├── README.md
# ├── data/
# │   ├── counts.csv
# │   └── metadata.csv
# ├── pandas_example.py
# ├── numpy_example.py
# └── scikit_learn_example.py

# --------------------
# 1. pandas_example.py
# --------------------
import pandas as pd

# Load synthetic RNA-Seq counts
df_counts = pd.read_csv('data/counts.csv', index_col=0)
print("First 5 rows of raw counts:")
print(df_counts.head())

# Filter genes with low expression (sum across samples > 10)
df_filtered = df_counts[df_counts.sum(axis=1) > 10]
print("\nFiltered genes (sum > 10):")
print(df_filtered.head())

# Load sample metadata
metadata = pd.read_csv('data/metadata.csv', index_col=0)
print("\nMetadata:")
print(metadata.head())

# Merge counts with metadata (samples as rows)
df_merged = df_filtered.T.merge(metadata, left_index=True, right_index=True)
print("\nMerged counts with metadata:")
print(df_merged.head())

# Save filtered counts for next steps
df_filtered.to_csv('data/filtered_counts.csv')

# --------------------
# 2. numpy_example.py
# --------------------
import pandas as pd
import numpy as np

# Load filtered counts
df = pd.read_csv('data/filtered_counts.csv', index_col=0)

# Convert to NumPy array for normalization
counts = df.values

# Counts per million (CPM)
counts_sum = counts.sum(axis=0)
cpm = (counts / counts_sum) * 1e6

# Log2 transformation
log_cpm = np.log2(cpm + 1)

# Back to DataFrame
df_norm = pd.DataFrame(log_cpm, index=df.index, columns=df.columns)
print("Normalized log2 CPM counts:")
print(df_norm.head())

# Save normalized counts
df_norm.to_csv('data/normalized_counts.csv')

# --------------------
# 3. scikit_learn_example.py
# --------------------
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load normalized counts
df_norm = pd.read_csv('data/normalized_counts.csv', index_col=0)

# PCA on samples (samples as rows)
data_samples = df_norm.T
pca = PCA(n_components=2)
principal_components = pca.fit_transform(data_samples)

# Create DataFrame for PCA plot
pca_df = pd.DataFrame(principal_components, columns=['PC1', 'PC2'])
pca_df['Condition'] = ['Control', 'Control', 'Control', 'Treatment', 'Treatment', 'Treatment']

# Plot PCA
plt.figure(figsize=(6,5))
colors = ['blue' if c=='Control' else 'red' for c in pca_df['Condition']]
plt.scatter(pca_df['PC1'], pca_df['PC2'], c=colors, s=100)
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('PCA of RNA-Seq Samples')
plt.savefig('data/pca_plot.png')
plt.show()

# KMeans clustering on genes
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(df_norm)
df_norm['Cluster'] = clusters
print("Top genes with assigned clusters:")
print(df_norm.head())

# Save clustering result
df_norm.to_csv('data/gene_clusters.csv')

# --------------------
# 4. Synthetic data CSVs
# --------------------
# counts.csv
counts_csv = '''Gene,Sample1,Sample2,Sample3,Sample4,Sample5,Sample6
GeneA,100,120,90,300,320,310
GeneB,50,45,55,200,190,210
GeneC,0,0,5,10,15,20
GeneD,500,520,480,50,60,55
GeneE,200,210,190,400,420,410
GeneF,5,10,15,300,320,310
GeneG,1000,950,980,900,920,910
GeneH,25,30,28,50,55,53
GeneI,300,320,310,100,120,110
GeneJ,0,5,0,0,5,0'''

with open('data/counts.csv','w') as f:
    f.write(counts_csv)

# metadata.csv
metadata_csv = '''Sample,Condition
Sample1,Control
Sample2,Control
Sample3,Control
Sample4,Treatment
Sample5,Treatment
Sample6,Treatment'''

with open('data/metadata.csv','w') as f:
    f.write(metadata_csv)

# --------------------
# 5. README.md
# --------------------
readme_text = '''# NGS Python Pipeline

This repository demonstrates a simple RNA-Seq analysis pipeline using Python libraries:
- pandas (data manipulation)
- NumPy (normalization and log transformation)
- scikit-learn (PCA and clustering)

## Usage

1. Ensure all scripts and the `data/` folder are in the same directory.
2. Run `pandas_example.py` to load, filter, and merge data.
3. Run `numpy_example.py` to normalize counts.
4. Run `scikit_learn_example.py` to perform PCA and clustering.

Synthetic data is included for immediate use.
'''

with open('README.md','w') as f:
    f.write(readme_text)
